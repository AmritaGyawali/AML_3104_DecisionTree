{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Amrita Gyawali\n",
    "\n",
    "Student ID: C0865702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree assignment:\n",
    "\n",
    "Q1:. Describe the decision tree classifier algorithm and how it works to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is a machine learning technique that assists us in making predictions. It's like a tree, with each 'node' representing a question or choice, and it's utilised for two key concepts: classification and regression. The decision tree's basic components are: root nodes, internal nodes, leaf nodes, and branches. The tree begins at the top with the first question (root nodes), and proceeds down different branches of the tree depending on the answer until it reaches an answer at the bottom, which we term a 'leaf node.' This response represents our prediction or decision.\n",
    "\n",
    "A decision tree classifier is a flowchart that assists a computer in making decisions. It's especially important when we want the computer to decide which category something fits in. For example, it may determine whether an email is spam or not, or whether a fruit is an apple, banana, or orange based on attributes such as form and colour.\n",
    "\n",
    "Below is the overview of how decision tree classifier works:\n",
    "\n",
    "Starting Point: The data at the top of the decision tree is the starting point, sometimes referred to as the root node.\n",
    "\n",
    "Ask Questions: To divide the data into more manageable groupings, provide questions concerning features.\n",
    "\n",
    "Making a Decision: Select the feature and value that offer the best split.\n",
    "\n",
    "Repeat until you get to a leaf node by continuing to respond to questions and follow branches. The ultimate prediction (class label) is given by the leaf node.\n",
    "\n",
    "Class Prediction: The predicted category for your supplied data is indicated by the class label at the leaf node.\n",
    "\n",
    "Below is example for decision tree classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris() #loading iris dataset\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #spliting the dataset\n",
    "\n",
    "clf = DecisionTreeClassifier() #creating classifier\n",
    "\n",
    "clf.fit(X_train, y_train) #training classifier\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is the step-by-step explanation:\n",
    "\n",
    "1.Entropy: A dataset's entropy can be used to quantify impurity or disorder. The first step in decision tree classification is to figure out the dataset's overall entropy. The following is the formula for entropy:\n",
    "\n",
    "Entropy(S)=−p1∗log2(p1)−p2∗log2(p2)−...−pc∗log2(pc)\n",
    "\n",
    "where:\n",
    "\n",
    "The dataset is S.\n",
    "\n",
    "Within the dataset, the proportions of each class are denoted by p1, p2,..., pc.\n",
    "\n",
    "The entropy is 0 in the case of a totally pure dataset (one class). When mixed equally, there is a high level of entropy.\n",
    "\n",
    "2.Information Gain: we use information gain to choose the ideal feature for dataset splitting. It also helps to measure the entropy after splitting.The formula for information gain is:\n",
    "\n",
    "Information Gain(S,A)=Entropy(S)−∑v∈Values(A)∣S∣∣Sv∣∗Entropy(Sv)\n",
    "where:\n",
    "\n",
    "A is a feature.\n",
    "\n",
    "Values(A) are the possible values of feature A.\n",
    "\n",
    "S_v is the subset of data where feature A has value v.\n",
    "\n",
    "3.Splitting: after that, we create a subsets for splitted data with the help of selected features. A branch is created in the tree to represent each possible value of the feature; each branch might have more than one value.\n",
    "\n",
    "4.Recursion: Considering each subset of data to be a new dataset, we go through the procedure again for each one. Recursively building the tree is what's done here.\n",
    "\n",
    "5.Stopping Criteria: When a stopping requirement is satisfied—for example, by reaching a maximum depth or a minimum number of samples per leaf—we cease splitting.\n",
    "\n",
    "5.Leaf Nodes: The leaf nodes of the tree are where the expected class labels are found. Predictions are the majority class in a leaf node.\n",
    "\n",
    "6.Prediction: To forecast a new data point, we follow the branches of the tree from the root to a leaf using the feature values as a guide. The leaf's primary class is the final prediction.\n",
    "\n",
    "The objective of the decision tree classification technique is to build a tree structure that maximises information gain at every stage, producing predictions that are precise and effective.In decision tree classification, this mathematical understanding is utilised to direct feature selection and splitting, allowing the model to make decisions and predictions based on the properties of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the way we use decision classifier to solve a binary classificaition problem:\n",
    "\n",
    "1.Dataset Preparation: \n",
    "A dataset with examples of two classes—Class A (positive) and Class B (negative)—is what you start with.\n",
    "\n",
    "2.The Decision Tree's training:\n",
    "Using the decision tree classifier, you can construct a tree according to the characteristics of the input. The decision tree is created by asking yes/no questions about the data's attributes, to effectively distinguish between Class A and Class B.\n",
    "\n",
    "3.Making Predictions:\n",
    "To decide whether a new data point belongs to Class A or Class B, you feed its characteristics into the decision tree. Like a flowchart, the tree begins at the beginning and progresses through a series of questions. It eventually comes to a leaf where it states either \"You're in Class A\" or \"You're in Class B.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make\n",
    "predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric Intuition: Visualise the points in your data as a two-axes graph, like a map. Coordinates for any point reflect its characteristics, including size and colour. By creating borders, a decision tree classifier attempts to divide this map into areas. Different regions correspond to different categories, such as \"Yes\" or \"No,\" or \"Class A\" or \"Class B.\" The decision tree selects the most advantageous locations to establish these boundaries. It is comparable to identifying the appropriate lines on a map to separate different kinds of points.\n",
    "\n",
    "Making Prediction:\n",
    "\n",
    "Assume you have a roadmap with many routes. To estimate the placement of a new point:\n",
    "\n",
    "-The new point should be marked on the map based on its characteristics.\n",
    "\n",
    "-Commence at the map's root, or the starting point, and proceed down the pathways, or roads, at each intersection in a certain direction determined by the characteristics of the new point.\n",
    "\n",
    "-Until you come to a certain spot (a leaf) on the map, keep following the roads. Your prediction for the new point is represented by the category there.\n",
    "\n",
    "Finding the correct route to your goal is similar to utilising a map, where each intersection (internal node) directs you depending on the features, and the ultimate position (leaf) indicates your predicted arrival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category for the new data point: A\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "X_train = [[2, 3], [3, 3], [1, 2], [2, 2]]\n",
    "y_train = ['A', 'B', 'A', 'B']\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "new_data_point = [[2, 3]]\n",
    "\n",
    "prediction = clf.predict(new_data_point)\n",
    "\n",
    "print(\"Predicted category for the new data point:\", prediction[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a\n",
    "classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix is kind of a  table used for showing evaluations of given model that displays the number of examples that were classified correctly and wrongly. This tool is very useful to understand and calculate the model's performance metrics.\n",
    "The confusion matrix made of four terms. They are:\n",
    "True positive(TP): The term \"true positives\" (TP) refers to circumstances in which both the observed and projected values point to a favourable outcome.\n",
    "true negative(TN):These are the results that indicate a negative outcome based on both the observed and expected values.\n",
    "false positive (FP):This occurs when an observed value is genuinely negative but the anticipated value is positive. \n",
    "False negative(FN):This is the situation in which a positive value is observed while a negative value is predicted. \n",
    "\n",
    "Now with the help of these terms, we can compute various performance measures, which give you information about the effectiveness of your model. These metrics include accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be\n",
    "calculated from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually calculate the value of these evaluation metrics and we can also use scikit learn library in python as well. \n",
    "Below is example for manually calculating evaluation metrics:\n",
    "\n",
    "True Positives (TP): 296\n",
    "\n",
    "True Negatives (TN): 2732\n",
    "\n",
    "False Positives (FP): 792\n",
    "\n",
    "False Negatives (FN): 90\n",
    "\n",
    "Now, let's calculate precision, recall, and F1 score:\n",
    "\n",
    "Precision:\n",
    "\n",
    "How many of the positively anticipated cases really occurred is a measure of precision. When the model forecasts a favourable result, that tells us something about its accuracy.\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Precision = 296/ (296 + 792) =  0.272\n",
    "\n",
    "Recall:\n",
    "The recall metric, which is often referred to as sensitivity or true positive rate, estimates the proportion of real positive cases that were accurately predicted. It provides information on how well the model represents positive cases.\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "Recall = 296 / (296 + 90) = 0.76\n",
    "\n",
    "F1 Score:\n",
    "Balanced between recall and precision is the F1 score. All false positives and false negatives are considered in a single metric.\n",
    "\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "F1 Score = 2 * (0.272 * 0.766) / (0.272+ 0.766) = 2 * 0.208 / 1.038 = 0.416 / 1.038 = 0.401\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.27205882352941174\n",
      "Recall: 0.7668393782383419\n",
      "F1 Score: 0.40162822252374486\n"
     ]
    }
   ],
   "source": [
    "#below is example using scikit library:\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "TP = 296\n",
    "TN = 2732\n",
    "FP = 792\n",
    "FN = 90\n",
    "\n",
    "y_true = [1] * (TP + FN) + [0] * (TN + FP)\n",
    "y_pred = [1] * TP + [0] * FN + [1] * FP + [0] * TN\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and\n",
    "explain how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to select the right evaluation metric for a classification task since it has an immediate effect on how machine learning model performance is measured and evaluated. In addition to considering the data distribution, the selected information should represent the business or application goal. The different reasons why we should be attentive while choosing right evaluation metric are:\n",
    "\n",
    "a.\tAlignment with Business Objectives: The metric needs to match the goals of the company. For instance, recall may be more crucial than precision if you are dealing with fraud detection, as false negatives may be more costly than false positives. \n",
    "\n",
    "b.\tData Imbalance: Accuracy can be deceptive in datasets that are imbalanced, meaning that one class substantially outnumbers the other. A clearer picture of the model's performance in these situations can be obtained by examining precision, recall, and the F1-score.\n",
    "\n",
    "c.\tPerformance Interpretation: When making decisions, stakeholders frequently refer to the reported performance. Selecting a statistic that is simple to understand within the context of the issue can help with decision-making. \n",
    "\n",
    "To choose an appropriate evaluation metric, consider the following steps: \n",
    "\n",
    "a.\tExamine Your Data: Determine whether each class in your data has about the same amount of examples, or whether one class has much more examples than the others. It may be inaccurate to focus solely on total accuracy if one class outnumbers the other. \n",
    "\n",
    "b.\tBusiness Objectives: Consider your model's intended outcomes. Is it more vital, for instance, to ensure that no spam passes through a spam filter (even if some excellent emails are stopped) or that all good emails are delivered (even if some spam passes through too)?\n",
    "\n",
    "c.\tConsider the Impact of Errors: Examine the consequences of using an incorrect model. Making a mistake in a diagnosis could be more detrimental than correctly diagnosing something else (false positive).You can then choose which accuracy is most crucial. \n",
    "\n",
    "d.\tDetermine if the classification is binary or multi-class: While certain metrics can be extended to multi-class contexts, some are designed exclusively for binary classification challenges, so we need to be careful on the basis of that as well. \n",
    "\n",
    "e.\tTry other Metrics: Lastly, to obtain a comprehensive understanding of the model's performance, it is frequently helpful to compute a number of other metrics.\n",
    "\n",
    "By reducing each stage, you may determine which metric will tell you the most correctly whether your model is doing well for your specific situation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Provide an example of a classification problem where precision is the most important metric, and\n",
    "explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, accuracy may be the most crucial consideration for classifying trash. Let's look at an example of a recycling facility's waste sorting system.\n",
    "Example: Waste Sorting in a Recycling Facility\n",
    "Recycling facilities must automatically separate incoming waste into many categories, including general debris, recyclables (paper, glass, and plastic), and occasionally hazardous items. For this, automated conveyor belt systems equipped with robots, cameras, and/or sensors are frequently employed.\n",
    "\n",
    "Here, accuracy may be quite important, particularly if reducing contamination in recyclable materials is the main objective. This illustrates why precision is the most important factor.\n",
    "1.\tControl of Contamination: Contamination arises when non-recyclable materials are unintentionally combined with recyclables. For instance, if a non-recyclable item is mixed in with recyclable components, it may degrade the batch's overall quality and decrease or maybe completely eliminate its potential for recycling.\n",
    "2.\tImpact on the Environment: Recycling might harm the environment if it needs more expensive processing to remove contaminants from recycled materials. Tight waste sorting helps to lessen these harmful effects on the environment.\n",
    "3.\tResource Efficiency: Accurate sorting guarantees higher-quality recyclables that break down more quickly and effectively, cutting waste and protecting priceless resources.\n",
    "\n",
    "When it comes to recycling garbage sorting, accuracy is essential since it reduces false positives—items that aren't recyclable that are mistakenly classified as recyclables. Maintaining the integrity of the recycling process, avoiding contamination, cutting expenses, and protecting the advantages for the environment all depend on precision. Finding the ideal balance between recall and precision may be important to maintain the sustainability and caliber of recycling operations, depending on the particular goals and limitations of the sorting system. In this scenario, false negatives—recyclable materials that are mistakenly classified as non-recyclable—usually pose less of a threat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. Provide an example of a classification problem where recall is the most important metric and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to identifying ulcers in the medical field, recollection could be the most important factor in some situations. Let's examine one example:\n",
    "Example: Ulcer Detection in Diabetic Patients\n",
    "Diabetes patients frequently develop foot ulcers, which, if ignored, can become fatally infected and necessitate amputations. Medical professionals can use a range of diagnostic methods, including imaging and visual inspection, to identify the presence of foot ulcers.\n",
    "In this case, recall becomes crucial, and here's why:\n",
    "1.\tPatient safety: A mistaken negative diagnosis of an ulcer might have major consequences for the patient, including delayed treatment and potential complications. To prevent additional injuries, early notice and action are essential.\n",
    "2.\tMinimizing False Negatives: Making sure that the majority of true ulcers are identified accurately is the main goal. By reducing the number of ulcers that are overlooked, optimizing recall guarantees that patients who require care receive it as soon as feasible.\n",
    "3.\tMedical Resources: The effectiveness of resource allocation is increased by employing a recall-focused approach. This guarantees that individuals with ulcers will receive care from doctors first and that those without ulcers will undergo fewer needless tests.\n",
    "\n",
    "Since the major goals of ulcer identification are to precisely identify as many actual ulcers as possible and treat diabetic patients as soon as possible to avoid problems, memory (recalling and identifying ulcers) must be given high importance. The danger of missing a real ulcer is thought to be greater than the chance of experiencing some false alarms, even if having a higher recall rate may occasionally lead us to report an ulcer when there isn't (false positives). It's crucial to understand that the most crucial metric may vary depending on the particular objectives and constraints of the ulcer detection system. When resources are few or costly, we might have to strike a compromise between our ability to accurately recall ulcers and our memory for them.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
